{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMy/EHr4tOLTpf8QSoCnT6n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deoprakash/NLP_Tutorial/blob/main/TextVectorization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **IMDB Movie Text Vectorization**"
      ],
      "metadata": {
        "id": "s5g9bsUTRiMI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "RXDdFf7aNQzO"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import TextVectorization"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"NLP, is field of Artificial Intelligence\""
      ],
      "metadata": {
        "id": "p2vZWOeVNcgz"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sentence2 = \"India, is a country\""
      ],
      "metadata": {
        "id": "8fKqhtbKPPyk"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer = TextVectorization(\n",
        "    standardize = \"lower_and_strip_punctuation\", #convert all text to lower case and remove punctuation\n",
        "\n",
        "    max_tokens = 100, #size of dictionary\n",
        "    output_mode = 'int', #give unique integer to each word\n",
        "    output_sequence_length = 25 # max length of sentence\n",
        ")"
      ],
      "metadata": {
        "id": "3Q_0T_IuNjsb"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorize_layer.adapt(sentence)\n",
        "# vectorize_layer.adapt(sentence2)"
      ],
      "metadata": {
        "id": "Y-M4GNBlN4Aa"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorize_layer(sentence))\n",
        "# print(vectorize_layer(sentence2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65LfWCG0O4jN",
        "outputId": "769f520b-1fba-49ce-8259-c6ced2b2fbd2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor([3 4 6 2 7 5 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0], shape=(25,), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorize_layer.get_vocabulary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IFgWQNmQPkAN",
        "outputId": "fce9f52c-b0a3-4d95-ec82-5bf4198c5a76"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', '[UNK]', np.str_('of'), np.str_('nlp'), np.str_('is'), np.str_('intelligence'), np.str_('field'), np.str_('artificial')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vectorize_layer.get_vocabulary()[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "77v1cyBPPxzN",
        "outputId": "6bc38107-c643-408b-9716-3f2a486f341f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[UNK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SKFxSxxUQc8B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}